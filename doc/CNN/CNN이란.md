## CNN의 아이디어:인간 시각의 동작으로부터
CNN의 아이디어는 크게 3가지 영감으로부터 출발한다
#### 신경과학적 영감:인간의 시각 시스템과 유사한 동작
인간의 시각 시스템은, 사실 수많은 뉴런들이 합쳐져서 동작한다.  
그런데, 각 뉴런들은 사실 물체 전체에 대해서는 잘 알지 못한다고 한다.  
뉴런들은 각각 담당하는 부분과 담당하는 시각 자극이 있어, 당해당 부분에 특정한 시각 자극이 들어올 때만 반응을 보일 뿐, 물체 전체가 어떻게 생겼는지는 알지 못한다.  
물체 전체를 인식하는것은 사실 뉴런이 아니라 뉴런들에서 들어온 정보를 종합하는 뇌에서 이루어지는 것이다.  
이러한 아이디어를 바탕으로, 1998년 Yann Lecn et al 의 논문에서 CNN이 탄생하게 된다

#### 공학적 영감:이미지의 본질
bayesian 방식의 object detection은, 객체가 정확히 특정 위치에 있을 때만 기존 feature의 분포를 기반으로 분류가 가능하다.  
그러나 본질적으로 이미지는, 객체가 어디에 위치할 지 알 수 없는 것이 정상이다. 따라서 객체의 위치, 객체 주변 광원 유무 등과 관계 없이 객체를 찾을수 있어야 한다. 이를 불변성이라고 하는데, CNN 은 이미지의 불변성이 유지된다


## CNN에서 Convolutional Layer의 구조
#### Filter = Kernel
Convolutional Layer는, 이미지의 일부분을 인식해 해당 부분의 특성을 추출한다. 인간 뉴런이 이미지의 일부분을 인식하는 것과 동일하다. 이 Layer를 filter 또는 kernel 이라고 한다.  
해당 filter는 3x3 픽셀 사이즈에, 각 픽셀마다 고유한 weight를 지닌다. 이 weight를 학습시키는 것이 CNN의 학습이다.  

#### Convolutional 연산, Cross Correlation 연산
이미지 전체에 대해 필터를 이동시키며 적용하며 convolution 연산을 수행한다. convolution 연산은 수학적으로는 복잡한데, 이미지 상에서는 사실 elementwise 연산이다.  
그러나 실제적으로는 convolution 연산을 위해서는 필터에 음의 값을 취하는 추가 처리가 필요하기 때문에, 동일한 의미를 가지지만 부호만 바뀌는 Cross Correlation을 적용한다.  

#### Fused Multiply-Add(FMA)
Convolution 연산을 아래와 같이 수행한다. bias는 FMA가 끝나고 더해준다.

#### Padding
FMA를 적용하고 나면, 필연적으로 출력 Feature의 Height,Width가 원본 이미지보다 줄어든다. 이를 방지하기 위해 테두리에 아래와 같이 0를 넣어 둘러주는데, 이렇게 하면 출력 Feature의 Height,Width가 입력 이미지와 동일해진다.

#### Feature Map
filter를 통과한 결과를 모은 후, pooling 과정을 통해 중요한 데이터만 남기고 중요하지 않은 데이터는 다른 데이터와 통합하는과정을 거치는데, 이를 통해 feature map을 생성하게 된다  
생성된 feature map을 다음 레이어로 넘긴다

#### STride
Filter를 이동하는 단위이다. 높은 값으로 설정하면 건너뛰는 간격이 높아지므로 이미지 정보 손실 가능성이 있다.


## CNN에서 Fully Connected Layer를 쓰지 않는 이유
1. 맥락상으로 맞지 않다
2차원의 이미지를 처리하는데, Flatten된 Layer를 쓰는 것은 명백히 의미 손실의 가능성이 있다.
2. Parameter의 개수가 기하급수적으로 늘어난다
2차원 데이터는 width * height의 픽셀을 갖는다. 1픽셀을 1 노드에 대응시켜야 하므로 노드의 개수와 훈련해야할 weight가 굉장히 늘어난다

## 3차원 이미지 데이터(색상정보 등 포함)의 CNN
2차원과 동일하지만, 입력 데이터와 필터의 채널 차원수만 동일하게 맞춰주면 됨

