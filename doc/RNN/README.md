## 명세 정리

1 프로젝트 개요

머신러닝 방법들 중 신경망 네트워크(Neural Network), 그 중 인공지능이 다시 주목받게 만든 심층 신경망 네트워크(Deep Neural Network)를 사용하여 이미지 처리와 자연어 처리를 학습한다.

Sub PJT 2 - 이미지 모델로 특성을 뽑아내고 텍스트 모델에 전달하여 이미지를 묘사하는 텍스트를 생성한다.

Sub PJT 1에서 학습한 인공신경망을 확장시켜 이미지 데이터에 적합한 컨볼루션 신경망(Convolutional Neural Networks)과 순서가 있는 데이터에 적합한 순환 신경망(Recurrent Neural Networks)에 대해 학습하고 이 두 신경망을 합쳐 이미지 캡셔닝(Image Captioning) 모델을 구현한다.

이미지에서 물체의 형태를 인지하거나 색깔을 구별하는 등 특성을 뽑아내는 데에는 컨볼루션 신경망이 사용되며 뽑아낸 특성을 바탕으로 문장을 생성하는 역할은 순환 신경망이 담당한다.



2 프로젝트 목표

1) 컨볼루션 인공 신경망에 대한 이해 (이미지)

2) 순환 신경망에 대한 이해 (텍스트)

3) 이미지 캡셔닝 모델에 대한 이해

4) 데이터셋 분할과 성능 최적화에 대한 이해

5) 팀별 서비스 기획, 데이터셋 검색 및 모델 선정



3-1 기본 아키텍쳐

CNN 모델을 통해 이미지 특징 추출 -> RNN 모델로 전달 -> 추가로 토큰화 된 캡션 데이터(벡터)의 일부를 입력받음



3-2 프로젝트 구조

1) 전처리 과정

모델에 적합하게 데이터를 가공하는 것을 전처리 과정이라고 한다.

한 번만 시행해도 되는 전처리 : 캡션 데이터의 토큰화, 전체 데이터셋 분할 등

매번 시행해야 하는 전처리 : 불러온 데이터의 순서를 랜덤하게 섞는 과정, 배치 사이즈에 맞게 분할해 묶는 과정 등

전처리 과정은 사용하는 데이터셋, 모델, 학습 과정 디자인에 따라 추가 및 제외가 가능하니 프로젝트 진행 과정에서 고민해보아야 한다.

- 한 번만 시행해도 되는 부분

캡션들이 저장된 CSV 파일을 토대로 실제 이미지 경로와 이미지에 해당하는 토큰화 된 캡션을 묶고, 전체 데이터를 학습용 데이터 및 테스트용 데이터로 분할해 저장해 놓으면 추후 모델에 입력으로 전달할 때 유용하다. 이 과정에서어떤 단어가 토큰에 해당하는지 매핑 된 정보를 기록해놓은 토크나이저 또한 저장한다. 추가적으로 학습된 모델을 이용해 이미지의 특성을 뽑아 놓는 것도 가능하다.

- 매번 진행해야 하는 부분

학습하는지 또는 테스트를 진행하는지에 따라 다른 데이터셋을 불러오고, 생성된 토크나이저를 불러오는 과정도 여기에 포함된다. 또한 불러온 데이터셋에는 이미지 경로와 토큰화 된 캡션이 있기 때문에 실제 이미지 데이터와 토큰화 된 캡션을 바인딩해 텐서플로우 데이터셋으로 만들게 된다. 이 과정에서 랜덤성을 추가하기 위해 순서를 바꾸거나 뒤집는다던가 하는 Augmentation 을 많이 사용하기 때문에 매번 진행하게 된다. 테스트 시에는 순서 바꾸기와 Augmentation 이 들어가지 않도록 구현한다.



2) 학습 과정

전처리 과정을 통해 전달된 tf.data.Dataset에는 Encoder의 입력이 되는 이미지 데이터 또는 미리 뽑힌 특성 벡터와 토큰화된 캡션이 쌍으로 들어있다. 이것들은 Encoder에 들어가 Decoder의 입력 형식에 맞게 변환되어 나오며, Encoder 내부는 인공신경망을 통해 입력을 출력으로 변환시킨다.

Encoder의 결과값은 Decoder로 전달되며 이와 동시에 <start> 토큰의 인덱스가 Decoder로 전달된다. 그럼 Decoder는 순차적으로 이미지를 묘사하는 문장의 단어들을 생성한다. 이 때 토큰의 가지 수만큼의 길이를 가지는 벡터로 나온다. 이 결과값을 정답 캡션과 비교해 손실을 계산하고 이 손실을 기반으로 모델의 변수들을 학습하여 최적화가 진행되게 한다.



3) 테스트 과정

모델이 학습되고 나면 체크포인트 매니저를 이용해 학습된 Encoder와 Decoder의 변수들을 불러와 테스트 이미지에 대한 예측 캡션을 생성할 수 있다. 이미지의 캡션이 생성되는 과정까지는 학습과 동일하지만 결과 문장을 사람이 해석할 수 있게 바꿔주는 과정이 추가로 진행된다.





## RNN 기능/과제 목록

Req 2. 텍스트 데이터 전처리

2-1, 2-2,

Req 3. Dataset 생성 함수 구현

3-1, 

Req 5. 텍스트 모델(Decoder) 구현

5-1, 5-2, 5-3, 

Req 6, 7, 8은 합치고 마무리 과정? 둘 다 나눠서 해야 되는건가?





## 명세 3. 필수 지식 학습

1) [토큰화](./1_Tokenization.md)

2) [정수 인코딩](./Integer Encoding.md)

3) [임베딩](./3_WordEmbedding.md)

4) [순환 신경망 기초](./4_Recurrent_Neural_Network.md)

5) [LSTM & GRU](./5_LSTM.md)





## 명세 6. 심화 학습(RNN)

1) Text Summarization - Seq2seq 기법을 기반으로 문서 요약해주는 인공지능 모델 구현

2) Sentiment Analysis - Seq2seq 기법을 기반으로 감정 분석기를 구현

3) 공개 데이터셋 및 Kaggle

4) 오버피팅과 언더피팅 / 가중치 초기화 / 정규화

